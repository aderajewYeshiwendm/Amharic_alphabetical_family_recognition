{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2b7ed3-49b8-463e-9c14-56351125282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.13.0.90-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (1.6.1)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.76.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.13.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading opencv_python-4.13.0.90-cp37-abi3-manylinux_2_28_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.8/620.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:05\u001b[0m\n",
      "Using cached grpcio-1.76.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "Downloading ml_dtypes-0.5.4-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.13.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (414 kB)\n",
      "Installing collected packages: namex, libclang, termcolor, tensorboard-data-server, optree, opt_einsum, opencv-python, ml_dtypes, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [tensorflow]37m━━\u001b[0m \u001b[32m15/16\u001b[0m [tensorflow]]data-server]\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 keras-3.13.1 libclang-18.1.1 ml_dtypes-0.5.4 namex-0.1.0 opencv-python-4.13.0.90 opt_einsum-3.4.0 optree-0.18.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python numpy matplotlib scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae2eca7-dc32-4097-8376-e63de8f814cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images.\n",
      "Processing [1/4]: dataset0.jpg\n",
      "\n",
      "--- CALIBRATING: dataset0.jpg ---\n",
      "INSTRUCTIONS:\n",
      "1. A window will pop up (check your taskbar if you don't see it).\n",
      "2. Click the 4 corners: Top-Left -> Top-Right -> Bottom-Right -> Bottom-Left.\n",
      "3. Close the window after clicking 4 times.\n",
      "  ✓ Saved 420 images (6x augmented) from dataset0.jpg\n",
      "Processing [2/4]: dataset1.jpg\n",
      "\n",
      "--- CALIBRATING: dataset1.jpg ---\n",
      "INSTRUCTIONS:\n",
      "1. A window will pop up (check your taskbar if you don't see it).\n",
      "2. Click the 4 corners: Top-Left -> Top-Right -> Bottom-Right -> Bottom-Left.\n",
      "3. Close the window after clicking 4 times.\n",
      "  ✓ Saved 420 images (6x augmented) from dataset1.jpg\n",
      "Processing [3/4]: dataset2.jpg\n",
      "\n",
      "--- CALIBRATING: dataset2.jpg ---\n",
      "INSTRUCTIONS:\n",
      "1. A window will pop up (check your taskbar if you don't see it).\n",
      "2. Click the 4 corners: Top-Left -> Top-Right -> Bottom-Right -> Bottom-Left.\n",
      "3. Close the window after clicking 4 times.\n",
      "  ✓ Saved 420 images (6x augmented) from dataset2.jpg\n",
      "Processing [4/4]: dataset3.jpg\n",
      "\n",
      "--- CALIBRATING: dataset3.jpg ---\n",
      "INSTRUCTIONS:\n",
      "1. A window will pop up (check your taskbar if you don't see it).\n",
      "2. Click the 4 corners: Top-Left -> Top-Right -> Bottom-Right -> Bottom-Left.\n",
      "3. Close the window after clicking 4 times.\n",
      "  ✓ Saved 420 images (6x augmented) from dataset3.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# --- SET MATPLOTLIB TO INTERACTIVE MODE ---\n",
    "# This ensures the window pops up so you can click on it\n",
    "try:\n",
    "    import IPython\n",
    "    shell = IPython.get_ipython()\n",
    "    shell.enable_matplotlib(gui='qt')\n",
    "except:\n",
    "    pass  # Standard python script usage\n",
    "\n",
    "class DataAugmentor:\n",
    "    \"\"\"Generates 6 variations of a single character\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate(img, angle):\n",
    "        h, w = img.shape\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def shift(img, dx, dy):\n",
    "        h, w = img.shape\n",
    "        M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def zoom(img, scale):\n",
    "        h, w = img.shape\n",
    "        center_x, center_y = w // 2, h // 2\n",
    "        radius_x, radius_y = w // (2 * scale), h // (2 * scale)\n",
    "        min_x, max_x = int(center_x - radius_x), int(center_x + radius_x)\n",
    "        min_y, max_y = int(center_y - radius_y), int(center_y + radius_y)\n",
    "        cropped = img[min_y:max_y, min_x:max_x]\n",
    "        if cropped.size == 0: return img \n",
    "        return cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    @staticmethod\n",
    "    def thicken(img):\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        return cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def thin(img):\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        return cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "class MatplotlibGridExtractor:\n",
    "    def __init__(self, output_dir='dataset/train_augmented'):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.num_rows = 10 \n",
    "        self.num_cols = 7   \n",
    "        self.family_names = ['ha', 'le', 'hha', 'me', 'se', 're', 'sa', 'sha', 'qe', 'be']\n",
    "    \n",
    "    def augment_cell(self, img):\n",
    "        \"\"\"Creates 6x dataset: 1 Original + 5 Variations\"\"\"\n",
    "        if img is None or cv2.countNonZero(img) == 0: return {}\n",
    "        variations = {}\n",
    "        \n",
    "        # 1. Original\n",
    "        variations['orig'] = img\n",
    "        # 2. Rotation\n",
    "        angle = random.uniform(5, 10) * (1 if random.random() > 0.5 else -1)\n",
    "        variations['rot'] = DataAugmentor.rotate(img, angle)\n",
    "        # 3. Zoom\n",
    "        variations['zoom'] = DataAugmentor.zoom(img, random.uniform(1.1, 1.2))\n",
    "        # 4. Shift\n",
    "        dx, dy = random.randint(-3, 3), random.randint(-3, 3)\n",
    "        variations['shift'] = DataAugmentor.shift(img, dx, dy)\n",
    "        # 5. Bold\n",
    "        variations['bold'] = DataAugmentor.thicken(img)\n",
    "        # 6. Thin (fallback to rotation if image too thin)\n",
    "        thinned = DataAugmentor.thin(img)\n",
    "        variations['thin'] = thinned if cv2.countNonZero(thinned) > cv2.countNonZero(img) * 0.4 else DataAugmentor.rotate(img, -3)\n",
    "\n",
    "        return variations\n",
    "\n",
    "    def manual_calibrate(self, image_path):\n",
    "        \"\"\"\n",
    "        Uses MATPLOTLIB for the GUI to avoid OpenCV errors.\n",
    "        \"\"\"\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None: return None, None\n",
    "\n",
    "        # Convert to RGB for Matplotlib\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        print(f\"\\n--- CALIBRATING: {image_path.name} ---\")\n",
    "        print(\"INSTRUCTIONS:\")\n",
    "        print(\"1. A window will pop up (check your taskbar if you don't see it).\")\n",
    "        print(\"2. Click the 4 corners: Top-Left -> Top-Right -> Bottom-Right -> Bottom-Left.\")\n",
    "        print(\"3. Close the window after clicking 4 times.\")\n",
    "\n",
    "        # Create Plot Window\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(\"Click: TL -> TR -> BR -> BL\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Get 4 inputs from user\n",
    "        # timeout=-1 means wait forever until clicks happen\n",
    "        pts = plt.ginput(n=4, timeout=-1, show_clicks=True)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        if len(pts) == 4:\n",
    "            # Convert float coordinates to integers\n",
    "            points = [(int(x), int(y)) for x, y in pts]\n",
    "            return points, img\n",
    "        else:\n",
    "            print(\"Did not record 4 clicks. Skipping.\")\n",
    "            return None, None\n",
    "    \n",
    "    def extract_and_augment(self, image_path, sample_id):\n",
    "        calib_points, img = self.manual_calibrate(image_path)\n",
    "        if calib_points is None: return\n",
    "\n",
    "        # 1. Perspective Transform\n",
    "        pts1 = np.float32(calib_points)\n",
    "        widthA = np.sqrt(((pts1[1][0] - pts1[0][0]) ** 2) + ((pts1[1][1] - pts1[0][1]) ** 2))\n",
    "        heightA = np.sqrt(((pts1[3][0] - pts1[0][0]) ** 2) + ((pts1[3][1] - pts1[0][1]) ** 2))\n",
    "        maxWidth, maxHeight = int(widthA), int(heightA)\n",
    "        \n",
    "        pts2 = np.float32([[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]])\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        warped_grid = cv2.warpPerspective(gray, matrix, (maxWidth, maxHeight))\n",
    "        \n",
    "        # 2. Slice Grid\n",
    "        cell_w = maxWidth / self.num_cols\n",
    "        cell_h = maxHeight / self.num_rows\n",
    "        \n",
    "        total_saved = 0\n",
    "        for row in range(self.num_rows):\n",
    "            family = self.family_names[row]\n",
    "            for col in range(self.num_cols):\n",
    "                char_name = f\"{family}_{col + 1}\"\n",
    "                \n",
    "                # Coords with Margin\n",
    "                x1 = int(col * cell_w + cell_w * 0.15)\n",
    "                y1 = int(row * cell_h + cell_h * 0.15)\n",
    "                x2 = int((col + 1) * cell_w - cell_w * 0.15)\n",
    "                y2 = int((row + 1) * cell_h - cell_h * 0.15)\n",
    "                \n",
    "                cell_img = warped_grid[y1:y2, x1:x2]\n",
    "                \n",
    "                # Clean\n",
    "                if cell_img.size == 0: continue\n",
    "                filtered = cv2.bilateralFilter(cell_img, 9, 75, 75)\n",
    "                _, binary = cv2.threshold(filtered, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "                \n",
    "                # Check if empty\n",
    "                if cv2.countNonZero(binary) > 50:\n",
    "                    # Resize to standard\n",
    "                    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    if contours:\n",
    "                        c = max(contours, key=cv2.contourArea)\n",
    "                        x, y, w, h = cv2.boundingRect(c)\n",
    "                        roi = binary[y:y+h, x:x+w]\n",
    "                        \n",
    "                        # 3. Augment and Save\n",
    "                        # Resize to uniform 64x64 before saving/augmenting\n",
    "                        target = 64\n",
    "                        scale = min(48/w, 48/h)\n",
    "                        nw, nh = int(w*scale), int(h*scale)\n",
    "                        resized = cv2.resize(roi, (nw, nh))\n",
    "                        final = np.zeros((target, target), dtype=np.uint8)\n",
    "                        px, py = (target-nw)//2, (target-nh)//2\n",
    "                        final[py:py+nh, px:px+nw] = resized\n",
    "                        \n",
    "                        # Generate 6 versions\n",
    "                        aug_batch = self.augment_cell(final)\n",
    "                        self.save_batch(aug_batch, char_name, sample_id)\n",
    "                        total_saved += len(aug_batch)\n",
    "\n",
    "        print(f\"  ✓ Saved {total_saved} images (6x augmented) from {image_path.name}\")\n",
    "\n",
    "    def augment_cell(self, img):\n",
    "        \"\"\"Wrapper for data augmentor\"\"\"\n",
    "        augmentor = DataAugmentor()\n",
    "        # We instantiate it here or make methods static (I made them static above)\n",
    "        return MatplotlibGridExtractor.static_augment(img)\n",
    "\n",
    "    @staticmethod\n",
    "    def static_augment(img):\n",
    "        # Re-using the logic from previous step, but ensuring it's accessible\n",
    "        variations = {'orig': img}\n",
    "        angle = random.uniform(5, 10) * (1 if random.random() > 0.5 else -1)\n",
    "        variations['rot'] = DataAugmentor.rotate(img, angle)\n",
    "        variations['zoom'] = DataAugmentor.zoom(img, random.uniform(1.1, 1.2))\n",
    "        variations['shift'] = DataAugmentor.shift(img, random.randint(-3, 3), random.randint(-3, 3))\n",
    "        variations['bold'] = DataAugmentor.thicken(img)\n",
    "        thinned = DataAugmentor.thin(img)\n",
    "        variations['thin'] = thinned if cv2.countNonZero(thinned) > cv2.countNonZero(img) * 0.4 else DataAugmentor.rotate(img, -3)\n",
    "        return variations\n",
    "\n",
    "    def save_batch(self, batch, char_name, sample_id):\n",
    "        char_dir = self.output_dir / char_name\n",
    "        char_dir.mkdir(parents=True, exist_ok=True)\n",
    "        count = len(list(char_dir.glob('*.png')))\n",
    "        for type_name, img in batch.items():\n",
    "            cv2.imwrite(str(char_dir / f\"{count:04d}_{sample_id}_{type_name}.png\"), img)\n",
    "            count += 1\n",
    "\n",
    "    def batch_process(self, input_dir):\n",
    "        input_path = Path(input_dir)\n",
    "        files = sorted([f for f in input_path.glob('*') if f.suffix.lower() in ['.jpg', '.png']])\n",
    "        print(f\"Found {len(files)} images.\")\n",
    "        \n",
    "        for i, f in enumerate(files):\n",
    "            print(f\"Processing [{i+1}/{len(files)}]: {f.name}\")\n",
    "            self.extract_and_augment(f, f.stem)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extractor = MatplotlibGridExtractor(output_dir='dataset/train_augmented')\n",
    "    extractor.batch_process('scanned_sheets/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6c539c-38a9-4327-a8be-c1de0aebe176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python-headless 4.13.0.90\n",
      "Uninstalling opencv-python-headless-4.13.0.90:\n",
      "  Successfully uninstalled opencv-python-headless-4.13.0.90\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "extractor.extract_with_calibration(\n",
    "        'scanned_sheets/dataset79.jpg',\n",
    "        sample_id='person1_sheet1',\n",
    "        show_preview=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cbf2da1-ff8d-41e0-b1a7-c2bec4ea8d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (4.13.0.90)\n",
      "Requirement already satisfied: numpy>=2 in /home/aderajew/Downloads/anaconda3/lib/python3.13/site-packages (from opencv-python) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5e587-f8cd-4dbf-9a13-29de70d693c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
